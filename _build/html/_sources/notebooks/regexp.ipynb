{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Regular-expressions\" data-toc-modified-id=\"Regular-expressions-1\">Regular expressions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Use-as-a-filter\" data-toc-modified-id=\"Use-as-a-filter-1.1\">Use as a filter</a></span></li><li><span><a href=\"#Use-in-place-of-conditionals\" data-toc-modified-id=\"Use-in-place-of-conditionals-1.2\">Use in place of conditionals</a></span></li><li><span><a href=\"#Search-and-replace\" data-toc-modified-id=\"Search-and-replace-1.3\">Search and replace</a></span></li><li><span><a href=\"#Renaming-files\" data-toc-modified-id=\"Renaming-files-1.4\">Renaming files</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular expressions\n",
    "\n",
    "Regular expressions are an immensely powerful tool built into most modern computer languages. They are a type of formal grammar that allow you to match strings that match or mismatch a particular rule. [http://www.rexegg.com/regex-uses.html](Common uses) include checking if user input conforms to a desired pattern (e.g., 3 numbers followed by two numbers, followed by 3 numbers), do all sorts of complicated search-replace operations both in text-files and, e.g., renaming files.\n",
    "\n",
    "There are [https://www.amazon.com/Mastering-Regular-Expressions-Jeffrey-Friedl/dp/0596528124](entire books) written on regular expressions as well as [comprehensive online references](https://www.regular-expressions.info/). We'll only concern ourselves with a few basics here. \n",
    "\n",
    "Start by looking over the [first couple lessons of this tutorial](https://regexone.com/), paying special attention to the sidebar on right, which I reproduce below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntax | Meaning\n",
    "------------- |:-------------\n",
    "abc…\t |  Literal letters\n",
    "\\d\t | \tAny Digit\n",
    "\\D\t | \tAny Non-digit character\n",
    ".\t | \tAny Character\n",
    "\\.\t | \tPeriod (slash is an escape character)\n",
    "[abc]\t | \tOnly a, b, or c\n",
    "[^abc]\t | \tNot a, b, nor c\n",
    "[a-z]\t | \tCharacters a to z\n",
    "[0-9]\t | \tNumbers 0 to 9\n",
    "\\w\t | \tAny Alphanumeric character\n",
    "\\W\t | \tAny Non-alphanumeric character\n",
    "{m}\t | \tm Repetitions\n",
    "{m,n}\t | \tm to n Repetitions\n",
    "*\t | \tZero or more repetitions\n",
    "+\t | \tOne or more repetitions\n",
    "?\t | \tOptional character\n",
    "\\s\t | \tAny Whitespace\n",
    "\\S\t | \tAny Non-whitespace character\n",
    "^…$\t | \tStarts and ends\n",
    "(…)\t | \tCapture Group\n",
    "(a(bc))\t | \tCapture Sub-group\n",
    "(.*)\t | \tCapture all\n",
    "(abc&#124;def)\t | \tMatches abc or def\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use as a filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by reading in a file containing a bunch of words from the [American National Corpus](http://www.anc.org/) that have a frequency of at least 9. Here's a sample of what this file looks like.\n",
    "\n",
    "    word\tlemma\tpos\tfreq\n",
    "    the\tthe\tDT\t1081168\n",
    "    of\tof\tIN\t539793\n",
    "    and\tand\tCC\t466737\n",
    "    to\tto\tTO\t448519\n",
    "    a\ta\tDT\t406057\n",
    "    in\tin\tIN\t360853\n",
    "    is\tbe\tVBZ\t192975\n",
    "\n",
    "For those unfamiliar with language lingo, English lemmas are basically the word-stems, e.g., the lemma of *cars* is *car*; the lemma of *walking* is *walk*. pos stands for [*part of speech*](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html).\n",
    "\n",
    "Just to illustrate an alternate way of dealing with csv file, let's use the `csv` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csvfile = open('datasets/ANC-written-count_over9.txt', 'r')\n",
    "data = csv.DictReader(csvfile, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` is a [DictReader](https://docs.python.org/2/library/csv.html#csv.DictReader) object which is kind of like a list of dictionaries of the kind we made when reading in trial files, except unlike a list we can't access a particular element, but have to iterate through it. The advantage of this is that we don't need to hold the entire dataset in memory at the same time (important for very large datasets, but not an issue in the present case).\n",
    "\n",
    "Since memory is not an issue here, let's put all the unique words. We don't care about frequencies for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 48318 words\n"
     ]
    }
   ],
   "source": [
    "import re #import the python regexp module\n",
    "\n",
    "words = set([row['word'] for row in data])\n",
    "print \"We have\", len(words), \"words\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use some regular expressions starting with simple ones, and moving on to every slightly more complicated ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab words beginning with *q*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quickedit',\n",
       " 'qualifications',\n",
       " 'queue',\n",
       " 'quadrant',\n",
       " 'quarter',\n",
       " 'quartet',\n",
       " 'qol',\n",
       " 'queues',\n",
       " 'qida',\n",
       " 'quicker',\n",
       " 'quixtar',\n",
       " 'quadrupled',\n",
       " 'quaint',\n",
       " 'quarterfinal',\n",
       " 'quixote',\n",
       " 'quarry',\n",
       " 'quickened',\n",
       " 'quintiles',\n",
       " 'quarries',\n",
       " 'qur',\n",
       " 'qua',\n",
       " 'quivering',\n",
       " 'quenched',\n",
       " 'quentin',\n",
       " 'quilts',\n",
       " 'qualifying',\n",
       " 'queensland',\n",
       " 'quartets',\n",
       " 'quantitation',\n",
       " 'questioner',\n",
       " 'questioned',\n",
       " 'quartiles',\n",
       " 'quarrels',\n",
       " 'quibble',\n",
       " 'quinones',\n",
       " 'qaida',\n",
       " 'quine',\n",
       " 'quick-edit',\n",
       " 'quoting',\n",
       " 'qrna',\n",
       " 'queens',\n",
       " 'quarterbacks',\n",
       " 'questioning',\n",
       " 'qiagen',\n",
       " 'quiche',\n",
       " 'qiaquick',\n",
       " 'qrs',\n",
       " 'qus',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'quo',\n",
       " 'quadrangle',\n",
       " 'quintet',\n",
       " 'qingdao',\n",
       " 'qualifies',\n",
       " 'qualifier',\n",
       " 'qualified',\n",
       " 'quiet',\n",
       " 'quantiles',\n",
       " 'qtls',\n",
       " 'qualcomm',\n",
       " 'quetzalcoatl',\n",
       " 'questions',\n",
       " 'quips',\n",
       " 'quso',\n",
       " 'qualifiers',\n",
       " 'questionnaires',\n",
       " 'quiver',\n",
       " 'quark',\n",
       " 'quart',\n",
       " 'qassam',\n",
       " 'quickness',\n",
       " 'quote',\n",
       " 'quota',\n",
       " 'qadir',\n",
       " 'quarters',\n",
       " 'qatar',\n",
       " 'q\\xe9\\xe5\\xfc\\xe5\\xe7\\xe4\\xe7\\xf6\\xf3',\n",
       " 'qios',\n",
       " 'quantified',\n",
       " 'quarter-century',\n",
       " 'qaddafi',\n",
       " 'quantities',\n",
       " 'quantitate',\n",
       " 'question',\n",
       " 'qutb',\n",
       " 'quotient',\n",
       " 'quarterfinals',\n",
       " 'quintanilla',\n",
       " 'query',\n",
       " 'quakes',\n",
       " 'quaker',\n",
       " 'quarrel',\n",
       " 'quitting',\n",
       " 'quds',\n",
       " 'quaid',\n",
       " 'quail',\n",
       " 'quenching',\n",
       " 'quantification',\n",
       " 'qp',\n",
       " 'qu',\n",
       " 'qa',\n",
       " 'qb',\n",
       " 'qd',\n",
       " 'quadruple',\n",
       " 'quashed',\n",
       " 'quantitative',\n",
       " 'quirk',\n",
       " 'quickie',\n",
       " 'quiescent',\n",
       " 'queasy',\n",
       " 'qpak',\n",
       " 'quixotic',\n",
       " 'quantitated',\n",
       " 'quagmire',\n",
       " 'qualify',\n",
       " 'quizzes',\n",
       " 'qu\\xe9bec',\n",
       " 'quests',\n",
       " 'quartops',\n",
       " 'q\\xe7\\xed',\n",
       " 'quecreek',\n",
       " 'quantitatively',\n",
       " 'quantile',\n",
       " 'quieter',\n",
       " 'quantifying',\n",
       " 'quintessential',\n",
       " 'qrt-pcr',\n",
       " 'quay',\n",
       " 'quai',\n",
       " 'quartz',\n",
       " 'quality-of-life',\n",
       " 'qspline',\n",
       " 'quayle',\n",
       " 'quell',\n",
       " 'quotations',\n",
       " 'qualms',\n",
       " 'quit',\n",
       " 'quip',\n",
       " 'quiz',\n",
       " 'quid',\n",
       " 'quotation',\n",
       " 'quibbles',\n",
       " 'quindlen',\n",
       " 'quantify',\n",
       " 'quench',\n",
       " 'quadrants',\n",
       " 'quran',\n",
       " 'quintana',\n",
       " 'queen',\n",
       " 'quad',\n",
       " 'qwest',\n",
       " 'quinta',\n",
       " 'quickly',\n",
       " 'questionable',\n",
       " 'quasi',\n",
       " 'quash',\n",
       " 'quigley',\n",
       " 'quarreling',\n",
       " 'quartop',\n",
       " 'qing',\n",
       " 'quake',\n",
       " 'queried',\n",
       " 'queries',\n",
       " 'quadratic',\n",
       " 'qaeda',\n",
       " 'quays',\n",
       " 'qio',\n",
       " 'qin',\n",
       " 'quandary',\n",
       " 'quite',\n",
       " 'quits',\n",
       " 'quack',\n",
       " 'quest',\n",
       " 'quarterback',\n",
       " 'quayside',\n",
       " 'qtc',\n",
       " 'qtl',\n",
       " 'quickest',\n",
       " 'qe',\n",
       " 'quinn',\n",
       " 'quick-line',\n",
       " 'q-pna',\n",
       " 'quoted',\n",
       " 'quotes',\n",
       " 'qsp',\n",
       " 'quinean',\n",
       " 'questionnaire',\n",
       " 'quotas',\n",
       " 'quantum',\n",
       " 'querying',\n",
       " 'qureshi',\n",
       " 'quality',\n",
       " 'quartile',\n",
       " 'quenk',\n",
       " 'quilt',\n",
       " 'qualitatively',\n",
       " 'quill',\n",
       " 'quot',\n",
       " 'qu\\xe9b\\xe9cois',\n",
       " 'qualities',\n",
       " 'quasispecies',\n",
       " 'quintile',\n",
       " 'q',\n",
       " 'quantifiable',\n",
       " 'quackery',\n",
       " 'quinone',\n",
       " 'quietly',\n",
       " 'quickening',\n",
       " 'quebec',\n",
       " 'qianlong',\n",
       " 'quincy',\n",
       " 'quarterly',\n",
       " 'qualification',\n",
       " 'quilted',\n",
       " 'qualitative',\n",
       " 'quilting',\n",
       " 'quotable',\n",
       " 'queer',\n",
       " 'quick',\n",
       " 'qt',\n",
       " 'quirks',\n",
       " 'question-and-answer',\n",
       " 'quirky',\n",
       " 'quantity',\n",
       " 'quintas',\n",
       " 'quipped',\n",
       " 'qeis',\n",
       " 'quidditch',\n",
       " 'quaternary']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[curWord for curWord in words if re.findall('^q',curWord)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab all words begin with an *a* and end with an *i*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agassi',\n",
       " 'asci',\n",
       " 'adlai',\n",
       " 'antoni',\n",
       " 'assisi',\n",
       " 'armani',\n",
       " 'andrei',\n",
       " 'anti',\n",
       " 'audi',\n",
       " 'alexei',\n",
       " 'ascii',\n",
       " 'alibi',\n",
       " 'api',\n",
       " 'ajami',\n",
       " 'aulaqi',\n",
       " 'agnelli',\n",
       " 'abdelghani',\n",
       " 'acini',\n",
       " 'ami',\n",
       " 'afi',\n",
       " 'alumni',\n",
       " 'alveoli',\n",
       " 'arabi',\n",
       " 'agouti',\n",
       " 'arundhati',\n",
       " 'asahi',\n",
       " 'aci',\n",
       " 'ashkenazi',\n",
       " 'adi',\n",
       " 'amalfi',\n",
       " 'ali',\n",
       " 'accompli',\n",
       " 'ambani',\n",
       " 'afghani',\n",
       " 'abi',\n",
       " 'avi',\n",
       " 'ani',\n",
       " 'ari',\n",
       " 'abyssi']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[curWord for curWord in words if re.findall('^a\\w+i$',curWord)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab all words that begin with an *a*, followed by 4-6 letters and and on an *i*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agassi',\n",
       " 'antoni',\n",
       " 'assisi',\n",
       " 'armani',\n",
       " 'andrei',\n",
       " 'alexei',\n",
       " 'aulaqi',\n",
       " 'agnelli',\n",
       " 'alumni',\n",
       " 'alveoli',\n",
       " 'agouti',\n",
       " 'amalfi',\n",
       " 'accompli',\n",
       " 'ambani',\n",
       " 'afghani',\n",
       " 'abyssi']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[curWord for curWord in words if re.findall('^a\\w{4,6}i$',curWord)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab words that start with a *l*, end on an *t*, and contain a *t* somewhere in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blastocyst',\n",
       " 'brightest',\n",
       " 'bioterrorist',\n",
       " 'bittorrent',\n",
       " 'blatant',\n",
       " 'backstreet',\n",
       " 'butaprost',\n",
       " 'baptist',\n",
       " 'bestest',\n",
       " 'bartlett',\n",
       " 'bittersweet',\n",
       " 'betterment',\n",
       " 'butait',\n",
       " 'batshit']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[curWord for curWord in words if re.findall('^b\\w+t\\w+t$',curWord)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to exclude words that end on two *t*s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blastocyst',\n",
       " 'brightest',\n",
       " 'bioterrorist',\n",
       " 'bittorrent',\n",
       " 'blatant',\n",
       " 'backstreet',\n",
       " 'butaprost',\n",
       " 'baptist',\n",
       " 'bestest',\n",
       " 'bittersweet',\n",
       " 'betterment',\n",
       " 'butait',\n",
       " 'batshit']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[curWord for curWord in words if re.findall('^b\\w+t\\w+[^tt]t$',curWord)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get all the words containing the vowels a, e, i, o, in that order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['intraperitoneally',\n",
       " 'characterizations',\n",
       " 'catheterization',\n",
       " 'characterization',\n",
       " 'cardiorespiratory',\n",
       " 'categorization',\n",
       " 'carvedilol',\n",
       " 'compartmentalization',\n",
       " 'intraperitoneal',\n",
       " 'campesino',\n",
       " 'parameterization',\n",
       " 'chloramphenicol']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[curWord for curWord in words if re.findall('\\w+a+\\w+e+\\w+i+\\w+o+',curWord)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You know that saying [i before e except after c](https://en.wikipedia.org/wiki/I_before_E_except_after_C) (in which case it's i after e, like *receive*). Let's see how well this mnemonic holds up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out how many words there are that have *ie* vs. *ei* in them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ie words: 1439\n",
      "ei words: 483\n"
     ]
    }
   ],
   "source": [
    "print \"ie words:\", len([curWord for curWord in words if re.findall('ie',curWord)])\n",
    "print \"ei words:\", len([curWord for curWord in words if re.findall('ei',curWord)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidePrompt": false
   },
   "source": [
    "Now let's check what happens when we check for a 'c' preceding ie/ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cie words: 107\n",
      "cei words: 33\n"
     ]
    }
   ],
   "source": [
    "print \"cie words:\", len([curWord for curWord in words if re.findall('cie',curWord)])\n",
    "print \"cei words:\", len([curWord for curWord in words if re.findall('cei',curWord)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are actually *more* words that violate the mnemonic than those that obey it!\n",
    "What are these words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contingencies',\n",
       " 'democracies',\n",
       " 'species-specific',\n",
       " 'societal',\n",
       " 'consciences',\n",
       " 'insufficiently',\n",
       " 'tumefaciens',\n",
       " 'deficiency',\n",
       " 'sucient',\n",
       " 'dependencies',\n",
       " 'francie',\n",
       " 'marcie',\n",
       " 'self-sufficient',\n",
       " 'gracie',\n",
       " 'vacancies',\n",
       " 'inefficiencies',\n",
       " 'inefficient',\n",
       " 'inadequacies',\n",
       " 'omniscient',\n",
       " 'currencies',\n",
       " 'proficient',\n",
       " 'deficiencies',\n",
       " 'frequencies',\n",
       " 'sciences',\n",
       " 'potencies',\n",
       " 'subspecies',\n",
       " 'concierge',\n",
       " 'scientia',\n",
       " 'unscientific',\n",
       " 'science-fiction',\n",
       " 'delicacies',\n",
       " 'science',\n",
       " 'newscientist',\n",
       " 'efficiencies',\n",
       " 'efficiently',\n",
       " 'malignancies',\n",
       " 'conscience',\n",
       " 'redundancies',\n",
       " 'conscientious',\n",
       " 'prophecies',\n",
       " 'bureaucracies',\n",
       " 'pregnancies',\n",
       " 'ancients',\n",
       " 'constituencies',\n",
       " 'prescience',\n",
       " 'insufficiency',\n",
       " 'discrepancies',\n",
       " 'prescient',\n",
       " 'intricacies',\n",
       " 'sufficient',\n",
       " 'interspecies',\n",
       " 'societies',\n",
       " 'glacier',\n",
       " 'policies',\n",
       " 'scientists',\n",
       " 'lucie',\n",
       " 'glaciers',\n",
       " 'scientology',\n",
       " 'tendencies',\n",
       " 'deficient',\n",
       " 'species',\n",
       " 'btk-deficient',\n",
       " 'coefficient',\n",
       " 'fancies',\n",
       " 'fancied',\n",
       " 'coefficients',\n",
       " 'efficient',\n",
       " 'energy-efficient',\n",
       " 'ancient',\n",
       " 'neuroscientist',\n",
       " 'aberrancies',\n",
       " 'conspiracies',\n",
       " 'self-sufficiency',\n",
       " 'agencies',\n",
       " 'financiers',\n",
       " 'conscientiously',\n",
       " 'financier',\n",
       " 'scientifically',\n",
       " 'bankruptcies',\n",
       " 'scientific',\n",
       " 'society',\n",
       " 'proficiency',\n",
       " 'biosciences',\n",
       " 'sufficiently',\n",
       " 'insufficient',\n",
       " 'pricier',\n",
       " 'candidacies',\n",
       " 'emergencies',\n",
       " 'inefficiency',\n",
       " 'saucier',\n",
       " 'fancier',\n",
       " 'sufficiency',\n",
       " 'efficiency',\n",
       " 'suycient',\n",
       " 'neuroscience',\n",
       " 'quasispecies',\n",
       " 'pharmacies',\n",
       " 'science-based',\n",
       " 'hacienda',\n",
       " 'legacies',\n",
       " 'inaccuracies',\n",
       " 'efficacies',\n",
       " 'immunodeficiency',\n",
       " 'scientist',\n",
       " 'cross-species',\n",
       " 'competencies',\n",
       " 'inconsistencies']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[curWord for curWord in words if re.findall('cie',curWord)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a tricky one. Let's find words containing 4 *r*s (interspersed among other letters). One way to do this is to explicitly specify it... any character, r, any character, r.. etc. Like so.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extraterrestrials',\n",
       " 'counterterrorism',\n",
       " 'counterterrorist',\n",
       " 'extracurricular',\n",
       " 'extraterrestrial',\n",
       " 'refrigerators',\n",
       " 'grrrr',\n",
       " 'cardiorespiratory',\n",
       " 'refrigerator']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[curWord for curWord in words if re.findall('\\w*r+\\w*r+\\w*r+\\w*r+\\w*',curWord)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two shortcomings to this approach. The first is that if we want 3 or 5 matches, we need to explicitly remove or add code rather than changing a single number-of-matches parameter. Another shortcoming is that hyphenated words are excluded. We can add hyphens by replacing `\\w` with `[a-z\\-]`, but that makes the expression even longer. Here's a better solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extraterrestrials',\n",
       " 'counterterrorism',\n",
       " 'writer-director',\n",
       " 'reverse-transcribed',\n",
       " 'counterterrorist',\n",
       " 'extracurricular',\n",
       " 'extraterrestrial',\n",
       " 'refrigerators',\n",
       " 'grrrr',\n",
       " 'cardiorespiratory',\n",
       " 'corporate-reform',\n",
       " 'counter-terrorism',\n",
       " 'antiretroviral-experienced',\n",
       " 'reverse-transcription',\n",
       " 'refrigerator']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[curWord for curWord in words if re.findall('([^r]*r[^r]*){4}$',curWord)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's unpack that. We are matching a [group](https://www.regular-expressions.info/refcapture.html) which is demarcated by parentheses. The group pattern is: not-an-r (0 or more times), an r, and then not-an-r (0 or more times). We want words that match this pattern exactly 4 times. That gives us all the words containing four *r*s and anything in between them (including nothing, hence *grrrr*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use in place of conditionals\n",
    "\n",
    "Let's say we want to check whether an entered word is *color* or the British *colour*. We can do this with a conditional (`if \"color\" or \"colour\"`), but we can also use regular expressions (which scale much better than conditionals). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colour', 'color']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('colou?r','The British like to colour their colors')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cag'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variousWords = re.compile('[d|c][a|o][g|t]')\n",
    "variousWords.match('cog').group()\n",
    "variousWords.match('cag').group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some more examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gmail.com', 'wisc.edu']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#will match any numbers\n",
    "anyNums = re.compile('[0-9]+')\n",
    "anyNums.findall('There are 99 bottles of beer on the wall. 999....') #will return all matches\n",
    "anyNums.search('There are 99 bottles of beer on the wall. 999....').group() #will return just the first occurrence\n",
    "\n",
    "#two digit numbers from 00 to 59 or 80 to 89 \n",
    "someNums = re.compile('[0-5][0-9]|[8][0-9]')\n",
    "matches = [someNums.search(x).group() for x in 'It will match 54, 52, and 88, but not 7 or 92 or any of the letters'.split(' ') if someNums.search(x)]\n",
    "matches\n",
    "\n",
    "#We don’t need to compile regular expressions using re.compile. but it speeds things up when using the same rule over a large corpus.\n",
    "\n",
    "emailRegExGrouped = re.compile('([\\w.-]+)@([\\w.-]+)')\n",
    "#the parenthesis allow us to access groups -- the first group corresponds to the first matched part (before the @). The second group to the domain (e.g., wisc.edu(\n",
    "\n",
    "emailRegExGrouped.search('g.lupyan@gmail.com').groups()\n",
    "('g.lupyan', 'gmail.com')\n",
    "\n",
    "emailRegExGrouped.findall('g.lupyan@gmail.com lupyan@wisc.edu')\n",
    "#returns [('g.lupyan', 'gmail.com'), ('lupyan', 'wisc.edu')]\n",
    "\n",
    "#to get all the domains:\n",
    "[email[1] for email in emailRegExGrouped.findall('g.lupyan@gmail.com lupyan@wisc.edu')]\n",
    "#returns ['gmail.com', 'wisc.edu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search and replace\n",
    "\n",
    "All good text editors allow you to use regular expressions in search and replace. \n",
    "A simple usage case is searching for lines that begin or end with a certain character sequence. To find lines that begin with \"ab\", search for `^ab`. To find lines that end on `ies` search for `ies$`\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Make sure to enable regular-expression search by clicking on .* in Sublime text or checking the appropriate box (sometimes labeled Grep) in other text editors</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using regular expressions in search/replace, it becomes useful to use matching groups. \n",
    "\n",
    "For example, suppose you want to replace the occurrences of the following strings, which occur at the start of each line:\n",
    "```\n",
    "bdSubjCode_130\n",
    "badSbjCode_131\n",
    "baSubjCode_132\n",
    "badSubjCode_133\n",
    "badubjCode_134\n",
    "BadSubjCode_135\n",
    "```\n",
    "with \n",
    "\n",
    "```\n",
    "MYSUBJCODE_130\n",
    "MYSUBJCODE_131\n",
    "MYSUBJCODE_132\n",
    "MYSUBJCODE_133\n",
    "MYSUBJCODE_134\n",
    "MYSUBJCODE_135\n",
    "```\n",
    "You *could* manually do search replaces for each one. But if you have a hundred of these, that gets tedious fast and is a recipe for errors.\n",
    "\n",
    "Here's a much better solution. Simply search for:\n",
    "\n",
    "`(^\\w+_)([0-9]+)`\n",
    "\n",
    "and replace with\n",
    "\n",
    "`MYSUBJCODE_\\2`\n",
    "\n",
    "The \\2 refers to the second group, i.e., the number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another example. Delete all the lines that start with some letters and end in 'ing':\n",
    "\n",
    "Search:\n",
    "`(^\\w+ing).*`\n",
    "Replace with: nothing\n",
    "\n",
    "Now you can do another search and replace, searching for\n",
    "`\\n+`\n",
    "and replacing with\n",
    "`\\n`\n",
    "To get rid of multiple newlines that the first search/replace may have created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same logic to rename files. You can do this in python or by using GUI programs like [NameChanger](https://mrrsoftware.com/namechanger/) (Mac), or [Bulk Rename](http://www.bulkrenameutility.co.uk/Main_Intro.php) (PC). These programs allow you to do batch renaming of files using simple search/replace (e.g., replace `_` with `-` or through search/replace augmented by regular expressions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {
    "height": "509px",
    "left": "0px",
    "right": "978.636px",
    "top": "110px",
    "width": "185px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
