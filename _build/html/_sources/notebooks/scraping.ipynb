{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping with Beautiful Soup\n",
    "\n",
    "In this notebook, we'll see how to use the [Beautiful Soup](https://www.youtube.com/watch?v=FWxFsJUlBbw) library for some psychology-relevant webscraping tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get heading names in a Wikipedia article\n",
    "\n",
    "Let's begin by automatically grabbing The Simpsons character names from the *Simpson Family* [Wikipedia page](https://en.wikipedia.org/wiki/Simpson_family). Looking at the wiki article, we see that the character names are part of a bulleted list (produced by the html `<ul>` tag. Furthermore, they're bolded. Let's give that a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept and origins\n",
      "* Herbert \"Herb\" Powell\n",
      "* Abbie\n",
      "* Chet\n",
      "* Dr. Simpson\n",
      "* Stanley\n",
      "* Uncle Tyrone\n",
      "* Great-Aunt Hortense\n",
      "* Hugo Simpson\n",
      "* Mabel Simpson\n",
      "* Hiram Simpson\n",
      "* Virgil\n",
      "* Virgil Simpson\n",
      "* Eliza Simpson\n",
      "* Abraham Simpson\n",
      "* Grampa's parents\n",
      "* Cyrus\n",
      "* Rita LaFleur\n",
      "* Amber Simpson\n",
      "Creation\n",
      "* Herbert \"Herb\" Powell\n",
      "* Abbie\n",
      "* Chet\n",
      "* Dr. Simpson\n",
      "* Stanley\n",
      "* Uncle Tyrone\n",
      "* Great-Aunt Hortense\n",
      "* Hugo Simpson\n",
      "* Mabel Simpson\n",
      "* Hiram Simpson\n",
      "* Virgil\n",
      "* Virgil Simpson\n",
      "* Eliza Simpson\n",
      "* Abraham Simpson\n",
      "* Grampa's parents\n",
      "* Cyrus\n",
      "* Rita LaFleur\n",
      "* Amber Simpson\n",
      "Casting\n",
      "* Herbert \"Herb\" Powell\n",
      "* Abbie\n",
      "* Chet\n",
      "* Dr. Simpson\n",
      "* Stanley\n",
      "* Uncle Tyrone\n",
      "* Great-Aunt Hortense\n",
      "* Hugo Simpson\n",
      "* Mabel Simpson\n",
      "* Hiram Simpson\n",
      "* Virgil\n",
      "* Virgil Simpson\n",
      "* Eliza Simpson\n",
      "* Abraham Simpson\n",
      "* Grampa's parents\n",
      "* Cyrus\n",
      "* Rita LaFleur\n",
      "* Amber Simpson\n",
      "The Simpson family\n",
      "* Herbert \"Herb\" Powell\n",
      "* Abbie\n",
      "* Chet\n",
      "* Dr. Simpson\n",
      "* Stanley\n",
      "* Uncle Tyrone\n",
      "* Great-Aunt Hortense\n",
      "* Hugo Simpson\n",
      "* Mabel Simpson\n",
      "* Hiram Simpson\n",
      "* Virgil\n",
      "* Virgil Simpson\n",
      "* Eliza Simpson\n",
      "* Abraham Simpson\n",
      "* Grampa's parents\n",
      "* Cyrus\n",
      "* Rita LaFleur\n",
      "* Amber Simpson\n",
      "Homer Simpson\n",
      "* Herbert \"Herb\" Powell\n",
      "* Abbie\n",
      "* Chet\n",
      "* Dr. Simpson\n",
      "* Stanley\n",
      "* Uncle Tyrone\n",
      "* Great-Aunt Hortense\n",
      "* Hugo Simpson\n",
      "* Mabel Simpson\n",
      "* Hiram Simpson\n",
      "* Virgil\n",
      "* Virgil Simpson\n",
      "* Eliza Simpson\n",
      "* Abraham Simpson\n",
      "* Grampa's parents\n",
      "* Cyrus\n",
      "* Rita LaFleur\n",
      "* Amber Simpson\n",
      "Marge Simpson\n",
      "* Herbert \"Herb\" Powell\n",
      "* Abbie\n",
      "* Chet\n",
      "* Dr. Simpson\n",
      "* Stanley\n",
      "* Uncle Tyrone\n",
      "* Great-Aunt Hortense\n",
      "* Hugo Simpson\n",
      "* Mabel Simpson\n",
      "* Hiram Simpson\n",
      "* Virgil\n",
      "* Virgil Simpson\n",
      "* Eliza Simpson\n",
      "* Abraham Simpson\n",
      "* Grampa's parents\n",
      "* Cyrus\n",
      "* Rita LaFleur\n",
      "* Amber Simpson\n",
      "Bart Simpson\n",
      "* Herbert \"Herb\" Powell\n",
      "* Abbie\n",
      "* Chet\n",
      "* Dr. Simpson\n",
      "* Stanley\n",
      "* Uncle Tyrone\n",
      "* Great-Aunt Hortense\n",
      "* Hugo Simpson\n",
      "* Mabel Simpson\n",
      "* Hiram Simpson\n",
      "* Virgil\n",
      "* Virgil Simpson\n",
      "* Eliza Simpson\n",
      "* Abraham Simpson\n",
      "* Grampa's parents\n",
      "* Cyrus\n",
      "* Rita LaFleur\n",
      "* Amber Simpson\n",
      "Lisa Simpson\n",
      "* Herbert \"Herb\" Powell\n",
      "* Abbie\n",
      "* Chet\n",
      "* Dr. Simpson\n",
      "* Stanley\n",
      "* Uncle Tyrone\n",
      "* Great-Aunt Hortense\n",
      "* Hugo Simpson\n",
      "* Mabel Simpson\n",
      "* Hiram Simpson\n",
      "* Virgil\n",
      "* Virgil Simpson\n",
      "* Eliza Simpson\n",
      "* Abraham Simpson\n",
      "* Grampa's parents\n",
      "* Cyrus\n",
      "* Rita LaFleur\n",
      "* Amber Simpson\n",
      "Maggie Simpson\n",
      "* Herbert \"Herb\" Powell\n",
      "* Abbie\n",
      "* Chet\n",
      "* Dr. Simpson\n",
      "* Stanley\n",
      "* Uncle Tyrone\n",
      "* Great-Aunt Hortense\n",
      "* Hugo Simpson\n",
      "* Mabel Simpson\n",
      "* Hiram Simpson\n",
      "* Virgil\n",
      "* Virgil Simpson\n",
      "* Eliza Simpson\n",
      "* Abraham Simpson\n",
      "* Grampa's parents\n",
      "* Cyrus\n",
      "* Rita LaFleur\n",
      "* Amber Simpson\n",
      "Abe Simpson\n",
      "* Herbert \"Herb\" Powell\n",
      "* Abbie\n",
      "* Chet\n",
      "* Dr. Simpson\n",
      "* Stanley\n",
      "* Uncle Tyrone\n",
      "* Great-Aunt Hortense\n",
      "* Hugo Simpson\n",
      "* Mabel Simpson\n",
      "* Hiram Simpson\n",
      "* Virgil\n",
      "* Virgil Simpson\n",
      "* Eliza Simpson\n",
      "* Abraham Simpson\n",
      "* Grampa's parents\n",
      "* Cyrus\n",
      "* Rita LaFleur\n",
      "* Amber Simpson\n",
      "Mona Simpson\n",
      "* Herbert \"Herb\" Powell\n",
      "* Abbie\n",
      "* Chet\n",
      "* Dr. Simpson\n",
      "* Stanley\n",
      "* Uncle Tyrone\n",
      "* Great-Aunt Hortense\n",
      "* Hugo Simpson\n",
      "* Mabel Simpson\n",
      "* Hiram Simpson\n",
      "* Virgil\n",
      "* Virgil Simpson\n",
      "* Eliza Simpson\n",
      "* Abraham Simpson\n",
      "* Grampa's parents\n",
      "* Cyrus\n",
      "* Rita LaFleur\n",
      "* Amber Simpson\n",
      "Extended Simpson family\n",
      "* Herbert \"Herb\" Powell\n",
      "* Abbie\n",
      "* Chet\n",
      "* Dr. Simpson\n",
      "* Stanley\n",
      "* Uncle Tyrone\n",
      "* Great-Aunt Hortense\n",
      "* Hugo Simpson\n",
      "* Mabel Simpson\n",
      "* Hiram Simpson\n",
      "* Virgil\n",
      "* Virgil Simpson\n",
      "* Eliza Simpson\n",
      "* Abraham Simpson\n",
      "* Grampa's parents\n",
      "* Cyrus\n",
      "* Rita LaFleur\n",
      "* Amber Simpson\n",
      "The Bouvier family\n",
      "* Sideshow Bob\n",
      "* Lionel Hutz\n",
      "* Troy McClure\n",
      "* Disco Stu\n",
      "* Grampa Simpson\n",
      "Jacqueline Bouvier\n",
      "* Sideshow Bob\n",
      "* Lionel Hutz\n",
      "* Troy McClure\n",
      "* Disco Stu\n",
      "* Grampa Simpson\n",
      "Clancy Bouvier\n",
      "* Sideshow Bob\n",
      "* Lionel Hutz\n",
      "* Troy McClure\n",
      "* Disco Stu\n",
      "* Grampa Simpson\n",
      "Patty and Selma Bouvier\n",
      "* Sideshow Bob\n",
      "* Lionel Hutz\n",
      "* Troy McClure\n",
      "* Disco Stu\n",
      "* Grampa Simpson\n",
      "Ling Bouvier\n",
      "* Sideshow Bob\n",
      "* Lionel Hutz\n",
      "* Troy McClure\n",
      "* Disco Stu\n",
      "* Grampa Simpson\n",
      "Selma's husbands\n",
      "* Sideshow Bob\n",
      "* Lionel Hutz\n",
      "* Troy McClure\n",
      "* Disco Stu\n",
      "* Grampa Simpson\n",
      "Extended Bouvier family\n",
      "* Gladys Gurney\n",
      "* Great Uncle Hubert\n",
      "* Dot\n",
      "* Lou Gurney\n",
      "* Uncle Arthur\n",
      "Pets\n",
      "* Santa's Little Helper\n",
      "* Laddie\n",
      "Dogs\n",
      "* Santa's Little Helper\n",
      "* Laddie\n",
      "Cats\n",
      "* Snowball\n",
      "* Snowball I\n",
      "* Snowball II\n",
      "Other pets\n",
      "* Plopper\n",
      "* Mojo\n",
      "* Chirpy Boy\n",
      "* Bart Junior\n",
      "* Stampy\n",
      "* Strangles\n",
      "* Pokey\n",
      "* Princess\n",
      "* Pinchy\n",
      "References\n",
      "Bibliography\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Simpson_family\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content)\n",
    "\n",
    "for headline in soup('span', {'class' : 'mw-headline'}):\n",
    "    print headline.text\n",
    "    topics = headline.find_next('ul').find_all('b') #ul is bulletpoints; b is bold\n",
    "    for topic in topics:\n",
    "        print '*', topic.text       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some false alarms, but this generally works! You might wonder whether this is too much trouble to go through just to get the Simpsons headings. But of course the identical code will work on pretty much *any* wiki article. And that's really the point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape images from a Google Image Search\n",
    "\n",
    "Wouldn't it be neat if we could automatically download the images returned from a [Google Image Query](https://www.google.com/search?tbm=isch&sa=1&ei=4x3hWtaILpCJjwTKy7xA&q=biggest+dog&oq=biggest+dog). \n",
    "Here's one way to do it ([props to this repo](https://gist.github.com/genekogan/ebd77196e4bf0705db51f86431099e57))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barebones version of Google image scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "#import re\n",
    "import urllib2\n",
    "import os\n",
    "#import sys\n",
    "import json\n",
    "\n",
    "def get_soup(url,header):\n",
    "\treturn BeautifulSoup(urllib2.urlopen(urllib2.Request(url,headers=header)),'html.parser')\n",
    "\n",
    "query = \"cats\"\n",
    "save_directory = query\n",
    "max_images = 12\n",
    "\n",
    "url=\"https://www.google.com/search?q=\"+query+\"&source=lnms&tbm=isch\"\n",
    "header={'User-Agent':\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36\"}\n",
    "soup = get_soup(url,header)\n",
    "\n",
    "try:\n",
    "    os.stat(save_directory)\n",
    "except:\n",
    "    os.mkdir(save_directory)\n",
    "\n",
    "\n",
    "ActualImages=[]# contains the link for Large original images, type of  image\n",
    "for a in soup.find_all(\"div\",{\"class\":\"rg_meta\"}):\n",
    "    link , Type =json.loads(a.text)[\"ou\"]  ,json.loads(a.text)[\"ity\"]\n",
    "    ActualImages.append((link,Type))\n",
    "for i , (img , Type) in enumerate( ActualImages[0:max_images]):\n",
    "    try:\n",
    "        print 'retrieving image', i\n",
    "        req = urllib2.Request(img, headers={'User-Agent' : header})\n",
    "        raw_img = urllib2.urlopen(req).read()\n",
    "        if len(Type)==0:\n",
    "            f = open(os.path.join(save_directory , \"img\" + \"_\"+ str(i)+\".jpg\"), 'wb')\n",
    "        else :\n",
    "            f = open(os.path.join(save_directory , \"img\" + \"_\"+ str(i)+\".\"+Type), 'wb')\n",
    "        f.write(raw_img)\n",
    "        f.close()\n",
    "    except Exception as e:\n",
    "        print \"could not load : \"+img\n",
    "        print e\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google image scraping with some bells and whistles\n",
    "\n",
    "The code above does the job, but can be improved considerably. First, we can refactor it, dividing up the various calls into separate functions. Second, we can make the query, directory, and number of images desired be command-line arguments. The code below (slightly adapted from a post by [*hadsed*](https://gist.github.com/hadsed) [here](https://gist.github.com/genekogan/ebd77196e4bf0705db51f86431099e57). \n",
    "\n",
    "Among other things, the code demonstrates the use of the argument-parsing [`argparse`](https://docs.python.org/2.7/library/argparse.html) package which allows you to specify options at the terminal that your python program can see (e.g., the query string, number of images, etc). This code also demonstrates logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import itertools\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from urllib2 import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def configure_logging():\n",
    "\tlogger = logging.getLogger()\n",
    "\tlogger.setLevel(logging.DEBUG)\n",
    "\thandler = logging.StreamHandler()\n",
    "\thandler.setFormatter(\n",
    "\t\tlogging.Formatter('[%(asctime)s %(levelname)s %(module)s]: %(message)s'))\n",
    "\tlogger.addHandler(handler)\n",
    "\treturn logger\n",
    "\n",
    "logger = configure_logging()\n",
    "\n",
    "REQUEST_HEADER = { #this can be changed to simulate different types of browsers\n",
    "\t'User-Agent': \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36\"}\n",
    "\n",
    "\n",
    "def get_soup(url, header):\n",
    "\tresponse = urlopen(Request(url, headers=header))\n",
    "\treturn BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "def get_query_url(query):\n",
    "\treturn \"https://www.google.com/search?q=%s&source=lnms&tbm=isch\" % query\n",
    "\n",
    "def extract_images_from_soup(soup):\n",
    "\timage_elements = soup.find_all(\"div\", {\"class\": \"rg_meta\"})\n",
    "\tmetadata_dicts = (json.loads(e.text) for e in image_elements)\n",
    "\tlink_type_records = ((d[\"ou\"], d[\"ity\"]) for d in metadata_dicts)\n",
    "\treturn link_type_records\n",
    "\n",
    "def extract_images(query, num_images):\n",
    "\turl = get_query_url(query)\n",
    "\tlogger.info(\"Souping\")\n",
    "\tsoup = get_soup(url, REQUEST_HEADER)\n",
    "\tlogger.info(\"Extracting image urls\")\n",
    "\tlink_type_records = extract_images_from_soup(soup)\n",
    "\treturn itertools.islice(link_type_records, num_images)\n",
    "\n",
    "def get_raw_image(url):\n",
    "\treq = Request(url, headers=REQUEST_HEADER)\n",
    "\tresp = urlopen(req)\n",
    "\treturn resp.read()\n",
    "\n",
    "def save_image(raw_image, image_type, file_name, save_directory):\n",
    "\textension = image_type if image_type else 'jpg'\n",
    "\tsave_path = os.path.join(save_directory, file_name+ \".\" + extension)\n",
    "\tprint 'image_type is', image_type, 'path is', save_path\n",
    "\twith open(save_path, 'wb') as image_file:\n",
    "\t\timage_file.write(raw_image)\n",
    "\n",
    "def download_images_to_dir(query, images, save_directory, num_images):\n",
    "\tfor i, (url, image_type) in enumerate(images):\n",
    "\t\ttry:\n",
    "\t\t\tlogger.info(\"Making request (%d/%d): %s\", i, num_images, url)\n",
    "\t\t\traw_image = get_raw_image(url)\n",
    "\t\t\tfile_name = query.replace('+','_')+'_'+str(i)\n",
    "\t\t\tsave_image(raw_image, image_type, file_name, save_directory)\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tlogger.exception(e)\n",
    "\n",
    "def run(query, save_directory, num_images=100):\n",
    "\tquery = '+'.join(query.split())\n",
    "\tlogger.info(\"Extracting image links\")\n",
    "\timages = extract_images(query, num_images)\n",
    "\tlogger.info(\"Downloading images\")\n",
    "\ttry:\n",
    "\t\tos.stat(save_directory)\n",
    "\texcept:\n",
    "\t\tos.mkdir(save_directory)\n",
    "\tdownload_images_to_dir(query, images, save_directory, num_images)\n",
    "\tlogger.info(\"Finished\")\n",
    "\n",
    "def main():\n",
    "\tparser = argparse.ArgumentParser(description='Scrape Google images')\n",
    "\tparser.add_argument('-s', '--search', default='bananas', type=str, help='search term or phrase')\n",
    "\tparser.add_argument('-n', '--num_images', default=10, type=int, help='num images to save')\n",
    "\tparser.add_argument('-d', '--directory', default='.', type=str, help='save directory')\n",
    "\targs = parser.parse_args()\n",
    "\tif args.directory=='.':\n",
    "\t\targs.directory = args.search.replace(' ','_') #use query string as directory\n",
    "\tprint args.search, args.directory\n",
    "\trun(args.search, args.directory, args.num_images)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading more than 100 images requires simulating a scrolling action with a web-browser. This can be done by using Selenium. You'll need to [download it](https://www.seleniumhq.org/), and also download [Chromedriver](https://sites.google.com/a/chromium.org/chromedriver/downloads). Then incorporate the code provided by [*aaronsherwood*](https://gist.github.com/genekogan/ebd77196e4bf0705db51f86431099e57) into the code above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other useful resources: Scraping Reddit, Online News\n",
    "\n",
    "There's really enormous infrastructure for web scraping, e.g., [PRAW](http://www.storybench.org/how-to-scrape-reddit-with-python/) for scraping reddit, [newspaper](https://github.com/codelucas/newspaper) for scraping online news. See [here](http://bdewilde.github.io/blog/blogger/2012/11/26/web-scraping-and-html-parsing-2/) and [here](https://opensourceforu.com/2016/07/22843/) for more examples. A really creative example of scraping is [this blog post by Erik Bern](https://erikbern.com/2017/02/01/language-pitch.html) which bulk downloads pronunciations of words in various languages to examine whether there are consistent differences in pitch (fundamental frequency) between languages (Hint, yes. Finnish is Lowwww).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
